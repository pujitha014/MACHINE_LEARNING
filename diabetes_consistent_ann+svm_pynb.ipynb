{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pujitha014/MACHINE_LEARNING/blob/main/diabetes_consistent_ann%2Bsvm_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "cu604hheFsUY",
        "outputId": "052f2d84-6aa6-4390-a19d-04aed0e0219c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/diabetes.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-21ce17c27a67>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/diabetes.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/diabetes.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv(\"/content/diabetes.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.drop(\"Outcome\",axis=1).values\n",
        "y=df[\"Outcome\"].values"
      ],
      "metadata": {
        "id": "g0DFuFW9GlAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "x = scaler.fit_transform(x)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "SsFt1XvDF208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ffe0175-9fcc-4ea9-ba93-e6d662ef5a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.63994726  0.84832379  0.14964075 ...  0.20401277  0.46849198\n",
            "   1.4259954 ]\n",
            " [-0.84488505 -1.12339636 -0.16054575 ... -0.68442195 -0.36506078\n",
            "  -0.19067191]\n",
            " [ 1.23388019  1.94372388 -0.26394125 ... -1.10325546  0.60439732\n",
            "  -0.10558415]\n",
            " ...\n",
            " [ 0.3429808   0.00330087  0.14964075 ... -0.73518964 -0.68519336\n",
            "  -0.27575966]\n",
            " [-0.84488505  0.1597866  -0.47073225 ... -0.24020459 -0.37110101\n",
            "   1.17073215]\n",
            " [-0.84488505 -0.8730192   0.04624525 ... -0.20212881 -0.47378505\n",
            "  -0.87137393]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_classifier.fit(x, y)\n",
        "\n",
        "svm_predictions = svm_classifier.predict(x)\n",
        "\n",
        "svm_accuracy = np.mean(svm_predictions==y)\n",
        "print(f\"SVM Accuracy: {svm_accuracy}\")"
      ],
      "metadata": {
        "id": "xGBiPz8sk9es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(x)\n",
        "# x= np.column_stack((x, svm_predictions))\n"
      ],
      "metadata": {
        "id": "O5JfUouhluRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "o6KpNy1Em0g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVC\n",
        "# import numpy as np\n",
        "# svm_classifier = SVC(kernel='rbf',gamma=0.04)\n",
        "# svm_classifier.fit(x_train, y_train)\n",
        "\n",
        "# svm_predictions = svm_classifier.predict(x_test)\n",
        "\n",
        "# svm_accuracy = np.mean(svm_predictions==y_test)\n",
        "# print(f\"SVM Accuracy: {svm_accuracy}\")"
      ],
      "metadata": {
        "id": "3GIRq7v9FArV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(x_train)"
      ],
      "metadata": {
        "id": "q2slm_I3Kd75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVC\n",
        "# import numpy as np\n",
        "\n",
        "# svm_classifier = SVC(kernel='rbf',gamma=0.04)\n",
        "# svm_classifier.fit(x_train, y_train)\n",
        "\n",
        "# svm_predictions = svm_classifier.predict(x_test)\n",
        "\n",
        "# svm_accuracy = np.mean(svm_predictions==y_test)\n",
        "# print(f\"SVM Accuracy: {svm_accuracy}\")"
      ],
      "metadata": {
        "id": "0SQVqC2EqnSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#my code\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def relu(x):\n",
        "    # return np.maximum(0,x)   #relu\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def derivative(x):\n",
        "   # return (x > 0).astype(int)    #relu derivate\n",
        "     return x*(1-x)\n",
        "\n",
        "def bound(x):\n",
        "    return np.clip(x,-1,1)\n",
        "\n",
        "\n",
        "i_n=x.shape[1]\n",
        "h_n=12\n",
        "h_o=1\n",
        "\n",
        "\n",
        "w1 = np.random.randn(i_n, h_n)\n",
        "b1 = np.ones((1, h_n))\n",
        "w2 = np.random.randn(h_n, h_o)\n",
        "b2 = np.ones((1, h_o))\n",
        "\n",
        "\n",
        "l= 0.01\n",
        "error=0\n",
        "lt=np.array([])\n",
        "epoch=1000\n",
        "t=y_train.reshape(-1,1)\n",
        "i = x_train\n",
        "max_gradient_norm = 1.0\n",
        "\n",
        "# initial_lr=0.1\n",
        "# decay_rate = 1\n",
        "# decay_steps = 100\n",
        "\n",
        "for j in range(epoch):\n",
        "        # l=l+(l*(1/(j+1)))\n",
        "\n",
        "        # l = initial_lr *(decay_rate**(epoch//decay_steps))\n",
        "\n",
        "        hidden_o=relu(np.dot(i,w1)+b1)\n",
        "        final_o=relu(np.dot(hidden_o,w2)+b2)\n",
        "        output_error =final_o-t\n",
        "\n",
        "        error=np.mean((t - final_o) ** 2)\n",
        "        # if len(lt)!=0 and error>lt[-1] :\n",
        "        #     break;\n",
        "\n",
        "        final_e=derivative(final_o)*(output_error)\n",
        "        hidden_e=np.dot(final_e,w2.T)*derivative(hidden_o)\n",
        "\n",
        "        gradient_final_o=np.dot(hidden_o.T,final_e)\n",
        "        gradient_hidden_o=np.dot(i.T,hidden_e)\n",
        "\n",
        "        if np.linalg.norm(gradient_final_o) > max_gradient_norm:\n",
        "            gradient_final_o =gradient_final_o* max_gradient_norm /np.linalg.norm(gradient_final_o)\n",
        "        if np.linalg.norm (gradient_hidden_o) > max_gradient_norm:\n",
        "            gradient_hidden_o = gradient_hidden_o * max_gradient_norm /np.linalg.norm (gradient_hidden_o)\n",
        "\n",
        "        w2=bound(w2-l*np.where(gradient_final_o<0,gradient_final_o,0))\n",
        "        w1=bound(w1-l*np.where(gradient_hidden_o<0,gradient_hidden_o,0))\n",
        "\n",
        "        b2=bound(b2-l*final_e.sum(axis=0, keepdims=True))\n",
        "        b1=bound(b1-l*hidden_e.sum(axis=0, keepdims=True))\n",
        "\n",
        "\n",
        "        if j % 100 == 0:\n",
        "            print(f\"Epoch {j}, Loss: {error}\")\n",
        "        lt=np.append(lt,error)\n",
        "\n",
        "plt.plot(lt)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "hidden_o = relu(np.dot(x_test, w1) + b1)\n",
        "final_o = np.dot(hidden_o, w2) + b2\n",
        "predictions = np.where(final_o >= 0.5, 1, 0)\n",
        "temp=y_test.reshape(-1,1)\n",
        "accuracy = np.mean(predictions == temp)\n",
        "print(f\"ann Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "hiUNG2Huf4W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#my code\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def relu(x):\n",
        "    # return np.maximum(0,x)   #relu\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def derivative(x):\n",
        "   # return (x > 0).astype(int)    #relu derivate\n",
        "     return x*(1-x)\n",
        "\n",
        "def bound(x):\n",
        "    return np.clip(x,-1,1)\n",
        "\n",
        "\n",
        "i_n=x.shape[1]\n",
        "h_n=12\n",
        "h_o=1\n",
        "\n",
        "\n",
        "w1 = np.random.randn(i_n, h_n)\n",
        "b1 = np.ones((1, h_n))\n",
        "w2 = np.random.randn(h_n, h_o)\n",
        "b2 = np.ones((1, h_o))\n",
        "\n",
        "\n",
        "l= 0.01\n",
        "error=0\n",
        "lt=np.array([])\n",
        "epoch=1000\n",
        "t=y_train.reshape(-1,1)\n",
        "i = x_train\n",
        "max_gradient_norm = 1.0\n",
        "\n",
        "# initial_lr=0.1\n",
        "# decay_rate = 1\n",
        "# decay_steps = 100\n",
        "\n",
        "for j in range(epoch):\n",
        "\n",
        "        hidden_o=relu(np.dot(i,w1)+b1)\n",
        "        final_o=relu(np.dot(hidden_o,w2)+b2)\n",
        "        output_error =final_o-t\n",
        "\n",
        "        error=np.mean((t - final_o) ** 2)\n",
        "\n",
        "        final_e=derivative(final_o)*(output_error)\n",
        "        hidden_e=np.dot(final_e,w2.T)*derivative(hidden_o)\n",
        "\n",
        "        gradient_final_o=np.dot(hidden_o.T,final_e)\n",
        "        gradient_hidden_o=np.dot(i.T,hidden_e)\n",
        "\n",
        "        if np.linalg.norm(gradient_final_o) > max_gradient_norm:\n",
        "            gradient_final_o =gradient_final_o* max_gradient_norm /np.linalg.norm(gradient_final_o)\n",
        "        if np.linalg.norm (gradient_hidden_o) > max_gradient_norm:\n",
        "            gradient_hidden_o = gradient_hidden_o * max_gradient_norm /np.linalg.norm (gradient_hidden_o)\n",
        "\n",
        "        w2=bound(w2-l*np.where(gradient_final_o<0,gradient_final_o,0))\n",
        "        w1=bound(w1-l*np.where(gradient_hidden_o<0,gradient_hidden_o,0))\n",
        "\n",
        "        b2=bound(b2-l*final_e.sum(axis=0, keepdims=True))\n",
        "        b1=bound(b1-l*hidden_e.sum(axis=0, keepdims=True))\n",
        "\n",
        "\n",
        "        if j % 100 == 0:\n",
        "            print(f\"Epoch {j}, Loss: {error}\")\n",
        "        lt=np.append(lt,error)\n",
        "\n",
        "plt.plot(lt)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "hidden_o = relu(np.dot(x_test, w1) + b1)\n",
        "final_o = np.dot(hidden_o, w2) + b2\n",
        "predictions = np.where(final_o >= 0.5, 1, 0)\n",
        "temp=y_test.reshape(-1,1)\n",
        "accuracy = np.mean(predictions == temp)\n",
        "print(f\"ann Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "f-bHcfZ9nIFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Set the random seed for initialization\n",
        "# np.random.seed(42)\n",
        "\n",
        "# i_n=x.shape[1]\n",
        "# h_n=20\n",
        "# h_o=1\n",
        "\n",
        "\n",
        "# # Initialize the variables using random values\n",
        "# rng = np.random.default_rng()\n",
        "# w1 = rng.standard_normal((i_n, h_n))\n",
        "# b1 = np.ones((1, h_n))\n",
        "# w2 = rng.standard_normal((h_n, h_o))\n",
        "# b2 = np.ones((1, h_o))\n",
        "\n",
        "# # Print the initialized variables\n",
        "# print(\"w1:\", w1)\n",
        "# print(\"b1:\", b1)\n",
        "# print(\"w2:\", w2)\n",
        "# print(\"b2:\", b2)\n",
        "\n",
        "# # Reset the random seed\n",
        "# rng = np.random.default_rng()\n",
        "\n",
        "# # Generate new random numbers\n",
        "# # new_random_numbers = rng.standard_normal(5)\n",
        "# # print(\"New random numbers:\", new_random_numbers)"
      ],
      "metadata": {
        "id": "-_YA2KmhivR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate=0.1):\n",
        "        self.input_nodes = input_nodes\n",
        "        self.hidden_nodes = hidden_nodes\n",
        "        self.output_nodes = output_nodes\n",
        "        self.learning_rate = learning_rate\n",
        "        np.random.seed(42)\n",
        "\n",
        "        # Initialize weights band biases\n",
        "        self.w1 = np.random.randn(input_nodes, hidden_nodes)\n",
        "        self.b1 = np.ones((1, hidden_nodes))\n",
        "        self.w2 = np.random.randn(hidden_nodes, output_nodes)\n",
        "        self.b2 = np.ones((1, output_nodes))\n",
        "        np.random.seed()\n",
        "\n",
        "    def relu(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def bound(self, x):\n",
        "        return np.clip(x, -1, 1)\n",
        "\n",
        "    def train(self, x_train, y_train, epochs=1000):\n",
        "        lt = np.array([])\n",
        "        for j in range(epochs):\n",
        "            hidden_o = self.relu(np.dot(x_train, self.w1) + self.b1)\n",
        "            final_o = self.relu(np.dot(hidden_o, self.w2) + self.b2)\n",
        "\n",
        "            output_error = final_o - y_train\n",
        "            error = np.mean((y_train - final_o) ** 2)\n",
        "\n",
        "            final_e = self.derivative(final_o) * (output_error)\n",
        "            hidden_e = np.dot(final_e, self.w2.T) * self.derivative(hidden_o)\n",
        "\n",
        "            gradient_final_o = np.dot(hidden_o.T, final_e)\n",
        "            gradient_hidden_o = np.dot(x_train.T, hidden_e)\n",
        "\n",
        "            max_gradient_norm = 1.0\n",
        "            if np.linalg.norm(gradient_final_o) > max_gradient_norm:\n",
        "                gradient_final_o = gradient_final_o * max_gradient_norm / np.linalg.norm(gradient_final_o)\n",
        "            if np.linalg.norm(gradient_hidden_o) > max_gradient_norm:\n",
        "                gradient_hidden_o = gradient_hidden_o * max_gradient_norm / np.linalg.norm(gradient_hidden_o)\n",
        "\n",
        "            self.w2 = self.bound(self.w2 - self.learning_rate * np.where(gradient_final_o < 0, gradient_final_o, 0))\n",
        "            self.w1 = self.bound(self.w1 - self.learning_rate * np.where(gradient_hidden_o < 0, gradient_hidden_o, 0))\n",
        "\n",
        "            self.b2 = self.bound(self.b2 - self.learning_rate * final_e.sum(axis=0, keepdims=True))\n",
        "            self.b1 = self.bound(self.b1 - self.learning_rate * hidden_e.sum(axis=0, keepdims=True))\n",
        "\n",
        "            lt = np.append(lt, error)\n",
        "\n",
        "            # if j % 100 == 0:\n",
        "            #     print(f\"Epoch {j}, Loss: {error}\")\n",
        "        return lt\n",
        "\n",
        "    def predict(self, x_test):\n",
        "        hidden_o = self.relu(np.dot(x_test, self.w1) + self.b1)\n",
        "        final_o = np.dot(hidden_o, self.w2) + self.b2\n",
        "        predictions = np.where(final_o >= 0.5, 1, 0)\n",
        "        return predictions\n",
        "\n",
        "# # Example usage:\n",
        "# # # Instantiate the neural network with 20 hidden nodes\n",
        "# # input_nodes = x_train.shape[1]\n",
        "# # hidden_nodes = 20\n",
        "# # output_nodes = 1\n",
        "# # learning_rate = 0.1\n",
        "\n",
        "# # nn = NeuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
        "# # losses = nn.train(x_train, y_train.reshape(-1, 1))\n",
        "\n",
        "# # # Test the model\n",
        "\n",
        "\n",
        "# # plt.plot(losses)\n",
        "# # plt.xlabel('Epochs')\n",
        "# # plt.ylabel('Loss')\n",
        "# # plt.show()\n",
        "\n",
        "# # predictions = nn.predict(x_test)\n",
        "# # accuracy = np.mean(predictions == y_test.reshape(-1, 1))\n",
        "# # print(f\"ANN Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "nsZEg9m3UvFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import cross_val_score\n",
        "# from sklearn.svm import SVC\n",
        "\n",
        "# svm_classifier = SVC(kernel='rbf',gamma=0.04)\n",
        "\n",
        "# # Perform 5-fold cross-validation (for example)\n",
        "# scores = cross_val_score(svm_classifier, x_train, y_train, cv=6)\n",
        "\n",
        "# print(\"Cross-Validation Scores:\", scores)\n",
        "# print(\"Mean Accuracy:\", scores.mean())"
      ],
      "metadata": {
        "id": "5PmWEz0Ppv4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "n = 10\n",
        "\n",
        "models = []\n",
        "sample_size = len(x_train)\n",
        "print(sample_size)\n",
        "\n",
        "\n",
        "for i in range(n):\n",
        "    indices = np.random.choice(sample_size, sample_size, replace=True)\n",
        "    x_bootstrap = x_train[indices]\n",
        "    y_bootstrap = y_train[indices]\n",
        "\n",
        "    model = NeuralNetwork(x_bootstrap.shape[1], 12,1,0.01)\n",
        "    model.train(x_bootstrap,y_bootstrap.reshape(-1, 1))\n",
        "\n",
        "    models.append(model)\n",
        "\n",
        "predictions = []\n",
        "accuracies=[]\n",
        "for model in models:\n",
        "    y_pred = model.predict(x_test)\n",
        "    predictions.append(y_pred)\n",
        "    acc=np.mean(y_test.reshape(-1,1)==y_pred)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "ensemble_predictions = np.round(np.mean(predictions, axis=0)) >= 0.5\n",
        "# temp=y_test.reshape(-1,1)\n",
        "ensemble_accuracy = np.mean(y_test.reshape(-1,1)==ensemble_predictions)\n",
        "print(f\"Ensemble Accuracy: {ensemble_accuracy}\")\n",
        "print(accuracies)\n",
        "print(f\"max: {max(accuracies)}\")"
      ],
      "metadata": {
        "id": "jTzX5FqoimY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00107b73-ae3e-4116-ac75-0fb0e09c6398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "614\n",
            "Ensemble Accuracy: 0.7922077922077922\n",
            "[0.7597402597402597, 0.7857142857142857, 0.8311688311688312, 0.7987012987012987, 0.7597402597402597, 0.7337662337662337, 0.7792207792207793, 0.7597402597402597, 0.7922077922077922, 0.8051948051948052]\n",
            "max: 0.8311688311688312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # different accuracy\n",
        "\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# class NeuralNetwork:\n",
        "#     def __init__(self, input_size, hidden_nodes, output_size):\n",
        "#         self.input_size = input_size\n",
        "#         self.hidden_nodes = hidden_nodes\n",
        "#         self.output_size = output_size\n",
        "#         self.initialize_weights()\n",
        "\n",
        "#     def initialize_weights(self):\n",
        "#         self.weights = []\n",
        "#         self.biases = []\n",
        "\n",
        "#         layer_sizes = [self.input_size] + self.hidden_nodes + [self.output_size]\n",
        "#         np.random.seed(42)\n",
        "#         for i in range(len(layer_sizes) - 1):\n",
        "#             weight_matrix = np.random.randn(layer_sizes[i], layer_sizes[i+1])\n",
        "#             bias_vector = np.ones((1, layer_sizes[i+1]))\n",
        "#             self.weights.append(weight_matrix)\n",
        "#             self.biases.append(bias_vector)\n",
        "\n",
        "#     def relu(self, x):\n",
        "#         return 1 / (1 + np.exp(-x))\n",
        "\n",
        "#     def derivative(self, x):\n",
        "#         return x * (1 - x)\n",
        "\n",
        "#     # def relu(self, x):  # Change the activation function to tanh\n",
        "#     #     return np.tanh(x)\n",
        "\n",
        "#     # def derivative(self, x):  # Derivative of tanh\n",
        "#     #     return 1 - np.tanh(x)**2\n",
        "\n",
        "#     def bound(self, x):\n",
        "#         return np.clip(x, -1, 1)\n",
        "\n",
        "#     def train(self, x_train, y_train, learning_rate=0.1, max_epochs=2000, max_gradient_norm=1.0):\n",
        "#       self.loss_history = []\n",
        "#       t = y_train.reshape(-1, 1)\n",
        "\n",
        "#       for epoch in range(max_epochs):\n",
        "#           hidden_layers_output = [x_train]\n",
        "#           layer_input = x_train\n",
        "\n",
        "#           for i in range(len(self.hidden_nodes)):\n",
        "#               layer_input = self.relu(np.dot(layer_input, self.weights[i]) + self.biases[i])\n",
        "#               hidden_layers_output.append(layer_input)\n",
        "\n",
        "#           final_output = self.relu(np.dot(layer_input, self.weights[-1]) + self.biases[-1])\n",
        "\n",
        "#           error = np.mean((t - final_output) ** 2)\n",
        "\n",
        "#           final_error = self.derivative(final_output) * (final_output - t)\n",
        "#           backpropagated_error = [final_error]\n",
        "\n",
        "#           for i in range(len(self.hidden_nodes) - 1, -1, -1):\n",
        "#               error_at_layer = np.dot(backpropagated_error[-1], self.weights[i+1].T) * self.derivative(hidden_layers_output[i+1])\n",
        "#               backpropagated_error.append(error_at_layer)\n",
        "\n",
        "#           backpropagated_error.reverse()\n",
        "\n",
        "#           for i in range(len(self.hidden_nodes) + 1):\n",
        "#               gradient = np.dot(hidden_layers_output[i].T, backpropagated_error[i])\n",
        "#               gradient_norm = np.linalg.norm(gradient)\n",
        "\n",
        "#               if gradient_norm > max_gradient_norm:\n",
        "#                   gradient = gradient * max_gradient_norm / gradient_norm\n",
        "\n",
        "#               self.weights[i] = self.bound(self.weights[i] - learning_rate * gradient)\n",
        "#               self.biases[i] = self.bound(self.biases[i] - learning_rate * np.sum(backpropagated_error[i], axis=0, keepdims=True))\n",
        "\n",
        "#           self.loss_history.append(error)\n",
        "\n",
        "#           # if epoch % 100 == 0:\n",
        "#           #     print(f\"Epoch {epoch}, Loss: {error}\")\n",
        "\n",
        "#     def predict(self, x_test):\n",
        "#         hidden_layers_output = [x_test]\n",
        "#         layer_input = x_test\n",
        "\n",
        "#         for i in range(len(self.hidden_nodes)):\n",
        "#             layer_input = self.relu(np.dot(layer_input, self.weights[i]) + self.biases[i])\n",
        "#             hidden_layers_output.append(layer_input)\n",
        "\n",
        "#         final_output = np.dot(layer_input, self.weights[-1]) + self.biases[-1]\n",
        "#         predictions = np.where(final_output >= 0.5, 1, 0)\n",
        "\n",
        "#         return predictions\n",
        "\n",
        "#     def plot_loss_history(self):\n",
        "#         plt.plot(self.loss_history)\n",
        "#         plt.xlabel('Epochs')\n",
        "#         plt.ylabel('Loss')\n",
        "#         plt.show()\n",
        "\n",
        "#     def evaluate_accuracy(self, x_test, y_test):\n",
        "#         predictions = self.predict(x_test)\n",
        "#         temp = y_test.reshape(-1, 1)\n",
        "#         accuracy = np.mean(predictions == temp)\n",
        "#         return accuracy\n",
        "\n",
        "# nn = NeuralNetwork(input_size=x_train.shape[1], hidden_nodes=[20], output_size=1)\n",
        "\n",
        "# # nn.train(x_train, y_train,0.01,2000)\n",
        "\n",
        "# # nn.plot_loss_history()\n",
        "\n",
        "# # accuracy = nn.evaluate_accuracy(x_test, y_test)\n",
        "# # print(f\"ANN Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "fpZc54UDgs0_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}