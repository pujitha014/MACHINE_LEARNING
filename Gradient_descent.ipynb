{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjSkbSZfbmEWaskG2VSOvs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pujitha014/MACHINE_LEARNING/blob/main/Gradient_descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kamisetty Pujitha\n",
        "AP21110010909\n",
        "CSE-N**"
      ],
      "metadata": {
        "id": "dGpLI2Vq6xa3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient descent is an optimization algorithm used to minimize the cost function in machine learning models. It's particularly popular in training models like linear regression, neural networks, and logistic regression. The basic idea behind gradient descent is to iteratively move towards the minimum of the cost function by taking steps proportional to the negative of the gradient of the function at the current point."
      ],
      "metadata": {
        "id": "8J1E3fg76mPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "tWi9mzsaOe8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vWhiNPjOBWv"
      },
      "outputs": [],
      "source": [
        "def estimated_coeff(x,y):\n",
        "  beta0=0\n",
        "  beta1=0\n",
        "  alpha=0.01\n",
        "  n=np.size(x)\n",
        "  y_expected=np.zeros(n)\n",
        "\n",
        "  for i in range(1000):\n",
        "    for j in range(n):\n",
        "      y_expected[j]=beta0+beta1*x[j]\n",
        "      beta0=beta0+alpha*(y[j]-y_expected[j])\n",
        "      beta1=beta1+alpha*(y[j]-y_expected[j])\n",
        "  return beta0,beta1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1, 2, 2,5])\n",
        "y = np.array([2, 3, 4, 5,])\n",
        "\n",
        "beta0, beta1 = estimated_coeff(x, y)\n",
        "print(\"Estimated coefficients:\")\n",
        "print(\"Beta0:\", beta0)\n",
        "print(\"Beta1:\", beta1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwKykbFcU-50",
        "outputId": "f668137f-a249-43ff-b8ab-67140e583312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated coefficients:\n",
            "Beta0: 0.9954969464794071\n",
            "Beta1: 0.9954969464794071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def mean_absolute_error(y_true, y_pred):\n",
        "    return np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "def r_squared(y_true, y_pred):\n",
        "    y_mean = np.mean(y_true)\n",
        "    ss_tot = np.sum((y_true - y_mean)**2)\n",
        "    ss_res = np.sum((y_true - y_pred)**2)\n",
        "    return 1 - (ss_res / ss_tot)\n",
        "\n",
        "def linear_regression(x, y, learning_rate=0.01, n_iterations=1000):\n",
        "    beta0 = 0\n",
        "    beta1 = 0\n",
        "    n = np.size(x)\n",
        "    for _ in range(n_iterations):\n",
        "        y_pred = beta0 + beta1 * x\n",
        "        beta0 = beta0 + learning_rate * np.nanmean(y - y_pred) / n\n",
        "        beta1 = beta1 + learning_rate * np.nanmean((y - y_pred) * x) / n\n",
        "    return beta0, beta1\n",
        "\n",
        "diabetes_data = pd.read_csv('/content/tvlist.csv')\n",
        "diabetes_data.dropna(inplace=True)\n",
        "\n",
        "X = diabetes_data['TV'].values\n",
        "y = diabetes_data['Sales'].values\n",
        "\n",
        "beta0, beta1 = linear_regression(X, y)\n",
        "\n",
        "y_pred = beta0 + beta1 * X\n",
        "\n",
        "mae = mean_absolute_error(y, y_pred)\n",
        "\n",
        "r2 = r_squared(y, y_pred)\n",
        "\n",
        "regression_equation = f'y = {beta0} + {beta1}*x'\n",
        "\n",
        "print(\"Regression Equation:\", regression_equation)\n",
        "print(\"R-squared:\", r2)\n",
        "print(\"Mean Absolute Error:\", mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQwLvoTRaW1M",
        "outputId": "6d1c422a-e4bd-4cb0-952e-e3a125bb7bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Equation: y = 0.08891759884411707 + 0.08279837515479131*x\n",
            "R-squared: 0.1610041403030701\n",
            "Mean Absolute Error: 4.072365026063924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iQnIKhyc6jfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"tvlist.csv\")\n",
        "\n",
        "\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "\n",
        "X = np.hstack((np.ones((len(X), 1)), X))\n",
        "\n",
        "coefficients = np.dot(np.linalg.inv(np.dot(X.T, X)), np.dot(X.T, y))\n",
        "\n",
        "for i, coeff in enumerate(coefficients):\n",
        "    print(f\"beta {i}: {coeff}\")\n",
        "\n",
        "y_pred = np.dot(X, coefficients)\n",
        "\n",
        "\n",
        "y_mean = np.mean(y)\n",
        "ss_total = np.sum((y - y_mean) ** 2)\n",
        "ss_residual = np.sum((y - y_pred) ** 2)\n",
        "r_squared = 1 - (ss_residual / ss_total)\n",
        "\n",
        "mae = np.mean(np.abs(y - y_pred))\n",
        "\n",
        "print(\"\\nR-squared:\", r_squared)\n",
        "print(\"Mean Absolute Error:\", mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIFJxFdefd5G",
        "outputId": "44be471b-d0f3-4ac4-b3ff-3556cb8fe38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beta 0: 7.0325935491276965\n",
            "beta 1: 0.04753664043301968\n",
            "\n",
            "R-squared: 0.611875050850071\n",
            "Mean Absolute Error: 2.5498060389274864\n"
          ]
        }
      ]
    }
  ]
}